<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Tong Liu - New York University (NYU) | Personal Homepage</title>

  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description"
    content="Personal homepage of Tong Liu, a student at New York University (NYU). This page introduces Tong Liu's research experience.">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>


<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <!-- START: 这是新插入的导航栏 -->
          <!-- 导航栏 -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td
                  style="padding:10px;width:25%;text-align:center;vertical-align:middle;border-bottom:1px solid #ccc;">
                  <a href="index.html" class="nav-link">Home</a>
                </td>
                <td
                  style="padding:10px;width:25%;text-align:center;vertical-align:middle;border-bottom:1px solid #ccc;">
                  <a href="research.html" class="nav-link">Research</a>
                </td>
                <td
                  style="padding:10px;width:25%;text-align:center;vertical-align:middle;border-bottom:1px solid #ccc;">
                  <a href="publications.html" class="nav-link">Publications</a>
                </td>
                <td
                  style="padding:10px;width:25%;text-align:center;vertical-align:middle;border-bottom:1px solid #ccc;">
                  <a href="cv.html" class="nav-link">CV</a>
                </td>
              </tr>
            </tbody>
          </table>
          <!-- END: 导航栏结束 -->


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Tong Liu
                  </p>
                  <p>I'm a PhD candidate in the Department of <a
                      href="https://engineering.nyu.edu/academics/departments/electrical-and-computer-engineering">Electrical
                      and Computer Engineering</a> at <a href="https://www.nyu.edu/">New York University</a>, advised by
                    Prof. <a href="https://engineering.nyu.edu/faculty/zhong-ping-jiang">Zhong-Ping Jiang</a>. I work on
                    distributed optimization, reinforcement learning, systems theory, transportation, and robotics.
                  </p>

                  <p>I have been pursuing the solutions to the following questions:
                  <ul>
                    <li><b><i>Break a hard problem into parts—fine. But when do solutions to the parts add up to a
                          solution for the whole? </i></b></li>
                    <li><b><i>Is it possible to achieve the desired behavior using only coarse information about a
                          system, without detailed knowledge of its internal structure?</i></b></li>
                  </ul>
                  Systems theory and machine learning provide principled concepts to address these questions. If you are
                  interested, Please see the following
                  <strong>Research Statement</strong>.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:tl3049@nyu.edu">Email</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=LTH_3NgAAAAJ&hl=en">Google Scholar</a>
                    &nbsp;/&nbsp;
                    <a href="https://github.com/tl3049">Github</a> &nbsp;/&nbsp;
                    <a href="https://www.linkedin.com/in/tongliu1024/">Linkedin</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:37%;max-width:37%">
                  <a href="images/capbala.webp"><img
                      style="width:100%;max-width:100%;object-fit: cover; border-radius: 15px;" alt="profile photo"
                      src="images/capbala.webp" class="hoverZoomLink"></a>
                </td>
                <!-- <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/capbala.webp"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/capbala.webp" class="hoverZoomLink"></a>
              </td> -->
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>Research Statement</h2>
                  <p>
                    My research focuses on distributed optimization and reinforcement learning for multi-agent systems
                    with applications to transportation and robotics. Throughout my research, all of the effective
                    approaches are
                    particular solutions to the above two questions.
                  </p>
                  <p>
                    The first question is relevant to a wide range of engineering disciplines,
                    since we often break a complex system into smaller subsystems,
                    each with a specific goal. For example, when developing a web application,
                    the front end handles user interactions and the back end manages data storage.
                    In distributed optimization, the optimizer reduces the overall loss and the aggregator
                    ensures consensus among agents. In reinforcement learning, the actor
                    improves the policy and the critic evaluates the policy.
                    All of these cases relate to the first question.
                  </p>
                  <p>
                    Under what conditions can this structure ensure the overall goal?
                    In general, the two modules should be <strong>weakly coupled</strong>, i.e., the failure of
                    one module does not significantly affect the other.
                    This idea relates to the <a href="https://link.springer.com/article/10.1007/BF01211469" target="_blank"
                      style="color:inherit; text-decoration:underline;">small-gain theorem</a>
                    and <a href="https://epubs.siam.org/doi/book/10.1137/1.9781611971118" target="_blank"
                      style="color:inherit; text-decoration:underline;">time-scale separation</a> in systems theory,
                    which I have applied to robust
                    distributed optimization of complex networks.
                    The result is surprising: the objective can be guaranteed for rather general classes of uncertain
                    nonlinear systems
                    subject to disturbances, provided that appropriate modules are weakly coupled.
                    Of course, the weakly coupling condition is non-trivial, and right language should be used to
                    describe it.
                    Please see <strong>Robust Distributed Optimization</strong> in <a
                      href="https://tl3049.github.io/research.html" target="_blank"
                      style="color:inherit; text-decoration:underline;">Research</a> for details.
                  </p>
                  <p> This is a potential research direction in <em>large language models </em> (LLMs). 
                    As the available training data for LLMs is being exhausted, 
                    how to continue improving the performance will be a challenging problem. 
                    To this end, <em> self-learning </em> is a promising approach; however, 
                    how to design the self-learning module and ensure improvement of the overall performance 
                    remains an open question. The decomposition and weakly coupling ideas may offer insight: 
                    <a
                      href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback" target="_blank"
                      style="color:inherit; text-decoration:underline;">RLHF</a>  is an example in which the reward model
                    and the policy model are weakly coupled, 
                    and the overall performance can be improved by carefully updating the two models.</p>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
            </tbody>
          </table>

    </tbody>
  </table>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:center;font-size:small;">
            Last update on <span id="last-updated"></span> | Design and source code from <a
              href="https://jonbarron.info/">Jon Barron</a>'s website
          </p>
        </td>
      </tr>
    </tbody>
  </table>
  </td>
  </tr>
  </table>

  <script>
    // 显示当前页面的最后修改时间
    const lastMod = new Date(document.lastModified);
    document.getElementById('last-updated').textContent =
      lastMod.toLocaleDateString('en-US', {
        year: 'numeric',
        month: 'short',
        day: 'numeric'
      });
  </script>

</body>

</html>